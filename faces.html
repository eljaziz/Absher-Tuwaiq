<!doctype html>
<html lang="en">
<head>
<meta charset="utf-8" />
<meta name="viewport" content="width=device-width, initial-scale=1" />
<title>Emotion Detector + Extraction + History</title>

<style>
  body {
    margin:0;
    display:flex;
    background:#051F20;
    color:white;
    font-family:Arial, sans-serif;
    height:100vh;
    overflow:hidden;
  }


  .left {
    flex:1.4;
    display:flex;
    justify-content:center;
    align-items:center;
    padding:20px;
  }

  .stage {
    position:relative;
    width:760px;
    padding:14px;
    background:#051F20;
    border-radius:12px;
    box-shadow:0 14px 40px rgba(0,0,0,0.6);
  }

  video {
    width:720px;
    height:540px;
    border-radius:10px;
    background:black;
    transform:scaleX(-1);
  }

  canvas {
    position:absolute;
    left:14px;
    top:14px;
    width:720px;
    height:540px;
    pointer-events:none;
  }

  #status {
    margin-top:10px;
    text-align:center;
    color:#E37B3A;
    font-weight:bold;
  }

 
  .right {
    flex:0.7;
    padding:20px;
    background:#051F20;
    border-left:2px solid #222;
    display:flex;
    flex-direction:column;
  }

  .right h2 {
    color:#E37B3A;
    margin-bottom:12px;
  }

  #outputFace {
    width:280px;
    border-radius:12px;
    border:2px solid #E37B3A;
    background:black;
  }

 
  #historyList {
    margin-top:20px;
    overflow-y:auto;
    flex:1;
    padding-right:10px;
  }

  .history-item {
    display:flex;
    align-items:center;
    gap:10px;
    margin-bottom:14px;
    background:#1a1f24;
    padding:8px;
    border-radius:8px;
    border:1px solid #222;
  }

  .history-item img {
    width:60px;
    height:auto;
    border-radius:6px;
    border:1px solid #E37B3A;
  }

  .history-text {
    display:flex;
    flex-direction:column;
  }

  .emotion-label {
    font-weight:bold;
    color:#E37B3A;
  }

  .timestamp {
    font-size:12px;
    color:#cccccc;
  }

</style>
</head>

<body>


<div class="left">
  <div class="stage">
    <video id="video" autoplay muted playsinline></video>
    <canvas id="overlay" width="720" height="540"></canvas>
    <div id="status">Loading models...</div>
  </div>
</div>


<div class="right">
  <h2>Latest Extracted Face</h2>
  <img id="outputFace" src="">

  <h2 style="margin-top:25px;">History</h2>
  <div id="historyList"></div>
</div>


<script src="https://cdn.jsdelivr.net/npm/@vladmandic/face-api/dist/face-api.min.js"></script>

<script>
(async () => {

  const video   = document.getElementById("video");
  const canvas  = document.getElementById("overlay");
  const ctx     = canvas.getContext("2d");
  const status  = document.getElementById("status");
  const outFace = document.getElementById("outputFace");
  const historyList = document.getElementById("historyList");

  const MODEL_URL = "https://cdn.jsdelivr.net/npm/@vladmandic/face-api/model/";

  async function loadModels() {
    status.textContent = "Loading models...";
    await faceapi.nets.tinyFaceDetector.loadFromUri(MODEL_URL);
    await faceapi.nets.faceLandmark68TinyNet.loadFromUri(MODEL_URL);
    await faceapi.nets.faceExpressionNet.loadFromUri(MODEL_URL);
    status.textContent = "Models loaded. Starting camera...";
  }

  async function startCamera() {
    const stream = await navigator.mediaDevices.getUserMedia({
      video: { width: 720, height: 540 }, audio:false
    });
    video.srcObject = stream;

    return new Promise(resolve => {
      video.onloadedmetadata = () => { video.play(); resolve(); };
    });
  }

  function getDominantExpression(expressions) {
    let best = "neutral", bestVal = 0;
    for (const e in expressions)
      if (expressions[e] > bestVal) {
        best = e; bestVal = expressions[e];
      }
    return best.toUpperCase();
  }

  
  function addHistoryEntry(dataUrl, emotion) {
    const time = new Date();
    const ts = time.toLocaleTimeString("en-US", { hour12:false });

    const item = document.createElement("div");
    item.className = "history-item";

    item.innerHTML = `
      <img src="${dataUrl}">
      <div class="history-text">
        <div class="emotion-label">${emotion}</div>
        <div class="timestamp">${ts}</div>
      </div>
    `;

    historyList.prepend(item);
  }

 
  async function extractFace(video, box, emotion) {
    const rect = new faceapi.Rect(box.x, box.y, box.width, box.height);
    const faces = await faceapi.extractFaces(video, [rect]);
    if (!faces || faces.length === 0) return;

    const dataUrl = faces[0].toDataURL();

  
    outFace.src = dataUrl;

    
    addHistoryEntry(dataUrl, emotion);
  }

  
  const options = new faceapi.TinyFaceDetectorOptions({
    inputSize: 320,
    scoreThreshold: 0.5
  });

  let lastExtract = 0;

  async function detectLoop(time) {
    const det = await faceapi
      .detectAllFaces(video, options)
      .withFaceLandmarks(true)
      .withFaceExpressions();

    ctx.clearRect(0, 0, canvas.width, canvas.height);

    if (det.length === 0) {
      status.textContent = "No face detected.";
      requestAnimationFrame(detectLoop);
      return;
    }

    status.textContent = `Face(s) detected: ${det.length}`;

    for (const d of det) {
      const box = d.detection.box;
      const emotion = getDominantExpression(d.expressions);

      
      ctx.save();
      ctx.setTransform(-1, 0, 0, 1, canvas.width, 0);
      ctx.strokeStyle = "#00ff00";
      ctx.lineWidth = 3;
      ctx.strokeRect(box.x, box.y, box.width, box.height);
      ctx.restore();

      
      ctx.fillStyle = "#00c853";
      ctx.font = "26px Arial";
      ctx.fillText(emotion, canvas.width - (box.x + box.width/2), box.y - 10);

      
      if (time - lastExtract > 1200) {
        lastExtract = time;
        extractFace(video, box, emotion);
      }
    }

    requestAnimationFrame(detectLoop);
  }

  await loadModels();
  await startCamera();
  requestAnimationFrame(detectLoop);

})();
</script>

</body>
</html>

